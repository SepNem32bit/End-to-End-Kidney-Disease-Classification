{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#It goes back to the previous folder (main folder) as we're in research folder\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Data Science\\Python Assignment\\End to End Kidney Disease Detection\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#is a mapping object that represents the user’s OS environmental variables. It returns a dictionary having the user’s environmental variable as key and their values as value.\n",
    "os.environ['ML_FLOW_TRACKING_UI']='https://dagshub.com/SepNem32bit/End-to-End-Kidney-Disease-Classification.mlflow'\n",
    "os.environ['ML_FLOW_TRACKING_USERNAME']=\"\"\n",
    "os.environ['ML_FLOW_TRACKING_PASSWORD']=\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.keras.models.load_model(\"artifacts\\training_ML\\model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "#returning all config parameters which will be used in arrow function output entities\n",
    "#@dataclass(frozen=True) is a decorator in Python's dataclasses module that makes instances of the class immutable after creation. \n",
    "# When applied, it provides the following benefits:\n",
    "# Immutability: Once an obSject is created, you cannot change its attributes. This is enforced by raising an error if there is any attempt to modify the instance's fields.\n",
    "# Hashability: Instances of the class become hashable (i.e., you can use them as keys in dictionaries or add them to sets) as long as all their fields are hashable.\n",
    "@dataclass(frozen=True)\n",
    "class EvaluationMLConfig:\n",
    "    trained_model_path: Path\n",
    "    training_data: Path\n",
    "    mlflow_uri:str\n",
    "    all_params: dict\n",
    "    params_batch_size:int\n",
    "    params_image_size:list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the configuration manager in src config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DiseaseClassifier.constants import *\n",
    "from DiseaseClassifier.utils.common import read_yaml, create_directories, save_json\n",
    "\n",
    "\n",
    "    \n",
    "class ConfigurationManager:\n",
    "    def __init__(self,\n",
    "                 #from constants\n",
    "                 config_filepath=CONFIG_FILE_PATH,\n",
    "                 params_filepath=PARAMS_FILE_PATH):\n",
    "        #init file for referencing the config and params files\n",
    "        self.config=read_yaml(config_filepath)\n",
    "        self.params=read_yaml(params_filepath)\n",
    "        #we have artifacts_root in config file\n",
    "        #It'll go through directories and create artifacts folder and subfolders\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    #This method creates the directory structure needed for the base machine learning configuration \n",
    "    #and returns an instance of PrepareBaseMLConfig\n",
    "    #we've defined DataIngestionConfig class above\n",
    "    def get_evaluation_ML_config(self)->EvaluationMLConfig:\n",
    "\n",
    "        evaluation_ml_config=EvaluationMLConfig(\n",
    "            trained_model_path= \"artifacts\\training_ML\\model.h5\",\n",
    "            training_data= \"artifacts/data_ingestion/kidney-ct-scan-image-samples\",\n",
    "            mlflow_uri='https://dagshub.com/SepNem32bit/End-to-End-Kidney-Disease-Classification.mlflow',\n",
    "            all_params= self.params,\n",
    "            params_batch_size=self.params.BATCH_SIZE,\n",
    "            params_image_size=self.params.IMAGE_SIZE\n",
    "            )\n",
    "        return evaluation_ml_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config\\config.yaml\n"
     ]
    }
   ],
   "source": [
    "from DiseaseClassifier.constants import CONFIG_FILE_PATH\n",
    "print(CONFIG_FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import mlflow\n",
    "import mlflow.keras\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "\n",
    "#What kwargs Does:\n",
    "# It enables you to pass an arbitrary number of keyword arguments (arguments with names) to a function.\n",
    "# Inside the function, kwargs is treated as a dictionary, where each key corresponds to the argument name and each value corresponds to the argument value.\n",
    "\n",
    "class Evaluation:\n",
    "    def __init__(self,config:EvaluationMLConfig):\n",
    "        self.config=config\n",
    "\n",
    "    #This code was copied from the keras documentation\n",
    "    #This code configures TensorFlow's ImageDataGenerator objects to load and process image data from a directory for both training and validation purposes. \n",
    "    #It handles optional data augmentation for the training data and ensures that validation data is loaded WITHOUT augmentation\n",
    "    \n",
    "    def _valid_generator(self):\n",
    "        #It sets up data generators for both training and validation datasets using the images from a specified directory.\n",
    "        #The variable datagenerator_kwargs is used to pass common preprocessing settings to the ImageDataGenerator in your code, \n",
    "        #but it was not explicitly defined in the snippet. Typically, this dictionary would contain parameters that control how the images are preprocessed before being fed into the model.\n",
    "        datagenerator_kwargs = dict(\n",
    "            #This is used to normalize the pixel values in the images. For instance, rescale=1./255 scales pixel values from [0, 255] to [0, 1], which is common when feeding image data into neural networks.\n",
    "            rescale = 1./255,\n",
    "            #it will load the whole data then split\n",
    "            validation_split=0.30\n",
    "        )\n",
    "\n",
    "        #all properties for the dataflow\n",
    "        dataflow_kwargs = dict(\n",
    "            target_size=self.config.params_image_size[:-1],\n",
    "            batch_size=self.config.params_batch_size,\n",
    "            #Chooses how to resize the images\n",
    "            interpolation=\"bilinear\"\n",
    "        )\n",
    "        #The ImageDataGenerator is initialized using datagenerator_kwargs, which is presumably a dictionary containing common preprocessing steps\n",
    "        valid_datagenerator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "            **datagenerator_kwargs\n",
    "        )\n",
    "        \n",
    "        #generating validation data\n",
    "        self.valid_generator = valid_datagenerator.flow_from_directory(\n",
    "            directory=self.config.training_data,\n",
    "            subset=\"validation\",\n",
    "            shuffle=False,\n",
    "            **dataflow_kwargs\n",
    "        )\n",
    "\n",
    "    #independent function which can be accessed from anywhere\n",
    "    @staticmethod\n",
    "    def load_model(path:Path) -> tf.keras.Model:\n",
    "        return tf.keras.models.load_model(path)\n",
    "    \n",
    "\n",
    "\n",
    "    def evaluation(self):\n",
    "        self.model=self.load_model(self.config.trained_model_path)\n",
    "        self._valid_generator\n",
    "        self.score=self.model.evaluate(self.valid_generator)\n",
    "        self.save_score()\n",
    "\n",
    "    def save_score(self):\n",
    "        scores={\"loss\":self.score[0],\"accuracy\":self.score[1]}\n",
    "        #from common in utility\n",
    "        save_json(path=Path('score.json'),data=scores)\n",
    "\n",
    "\n",
    "    def log_into_mlflow(self):\n",
    "        mlflow.set_registry_uri(self.config.mlflow_uri)\n",
    "        tracking_url_type_store = urlparse(mlflow.get_tracking_uri()).scheme\n",
    "        # Start a run\n",
    "        with mlflow.start_run():\n",
    "            #logging all parameters and metrics\n",
    "            mlflow.log_params(self.config.all_params)\n",
    "            mlflow.log_metrics(\n",
    "                {\"loss\": self.score[0], \"accuracy\": self.score[1]}\n",
    "            )\n",
    "            # Model registry does not work with file store\n",
    "            if tracking_url_type_store != \"file\":\n",
    "\n",
    "                # Register the model\n",
    "                # There are other ways to use the Model Registry, which depends on the use case,\n",
    "                # please refer to the doc for more information:\n",
    "                # https://mlflow.org/docs/latest/model-registry.html#api-workflow\n",
    "                mlflow.keras.log_model(self.model, \"model\", registered_model_name=\"VGG16Model\")\n",
    "            else:\n",
    "                #saving the model\n",
    "                mlflow.keras.log_model(self.model, \"model\")\n",
    "\n",
    "\n",
    "# you can avoid creating a separate _valid_generator method by directly defining the validation data generator inside the evaluate method. \n",
    "# This keeps the code more concise, as the generator configuration is only needed within the context of the evaluation process.    \n",
    "#     def evaluate(self):\n",
    "#         # Load the model\n",
    "#         model = self.load_model()\n",
    "\n",
    "#         # Directly create the validation data generator\n",
    "#         valid_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "#             rescale=1.0 / 255, validation_split=0.30\n",
    "#         ).flow_from_directory(\n",
    "#             directory=self.config.training_data,\n",
    "#             target_size=self.config.params_image_size[:-1],\n",
    "#             batch_size=self.config.params_batch_size,\n",
    "#             interpolation=\"bilinear\",\n",
    "#             subset=\"validation\",\n",
    "#             shuffle=False\n",
    "#         )\n",
    "\n",
    "#         # Evaluate model and save score\n",
    "#         score = model.evaluate(valid_generator)\n",
    "#         scores = {\"loss\": score[0], \"accuracy\": score[1]}\n",
    "#         save_json(Path('score.json'), data=scores)\n",
    "\n",
    "#         # Log to MLflow\n",
    "#         self.log_to_mlflow(model, scores)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the data pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-10-29 16:13:04,999: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2024-10-29 16:13:05,036: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-10-29 16:13:05,038: INFO: common: created directory at: <class 'pathlib.Path'>]\n",
      "[2024-10-29 16:13:05,039: INFO: common: created directory at: <class 'pathlib.Path'>]\n",
      "[2024-10-29 16:13:08,754: WARNING: saving_utils: Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.]\n",
      "Found 40 images belonging to 2 classes.\n",
      "Found 160 images belonging to 2 classes.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown variable: <KerasVariable shape=(25088, 2), dtype=float32, path=dense/kernel>. This optimizer can only be called for the variables it was originally built with. When working with a new set of variables, you should recreate a new optimizer instance.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[6], line 9\u001b[0m\n",
      "\u001b[0;32m      7\u001b[0m     training\u001b[38;5;241m.\u001b[39mtrain()\n",
      "\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;32m----> 9\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\n",
      "Cell \u001b[1;32mIn[6], line 7\u001b[0m\n",
      "\u001b[0;32m      5\u001b[0m     training\u001b[38;5;241m.\u001b[39mget_base_model()\n",
      "\u001b[0;32m      6\u001b[0m     training\u001b[38;5;241m.\u001b[39mtrain_valid_generator()\n",
      "\u001b[1;32m----> 7\u001b[0m     \u001b[43mtraining\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\n",
      "Cell \u001b[1;32mIn[5], line 91\u001b[0m, in \u001b[0;36mTraining.train\u001b[1;34m(self)\u001b[0m\n",
      "\u001b[0;32m     88\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_per_epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_generator\u001b[38;5;241m.\u001b[39msamples \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_generator\u001b[38;5;241m.\u001b[39mbatch_size\n",
      "\u001b[0;32m     89\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidation_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalid_generator\u001b[38;5;241m.\u001b[39msamples \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalid_generator\u001b[38;5;241m.\u001b[39mbatch_size\n",
      "\u001b[1;32m---> 91\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[0;32m     92\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m     93\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams_epochs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m     94\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m     95\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#Defines how many batches of validation data will be processed after each epoch.\u001b[39;49;00m\n",
      "\u001b[0;32m     96\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m     97\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalid_generator\u001b[49m\n",
      "\u001b[0;32m     98\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m     99\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_model(path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mtrained_model_path,model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel)\n",
      "\n",
      "File \u001b[1;32md:\\Data Science\\Python Assignment\\End to End Kidney Disease Detection\\myenv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n",
      "\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n",
      "\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\n",
      "File \u001b[1;32md:\\Data Science\\Python Assignment\\End to End Kidney Disease Detection\\myenv\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py:237\u001b[0m, in \u001b[0;36mBaseOptimizer._check_variables_are_known\u001b[1;34m(self, variables)\u001b[0m\n",
      "\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m variables:\n",
      "\u001b[0;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_var_key(v) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainable_variables_indices:\n",
      "\u001b[1;32m--> 237\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n",
      "\u001b[0;32m    238\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown variable: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mv\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. This optimizer can only \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;32m    239\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbe called for the variables it was originally built with. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;32m    240\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen working with a new set of variables, you should \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;32m    241\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecreate a new optimizer instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;32m    242\u001b[0m         )\n",
      "\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown variable: <KerasVariable shape=(25088, 2), dtype=float32, path=dense/kernel>. This optimizer can only be called for the variables it was originally built with. When working with a new set of variables, you should recreate a new optimizer instance."
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config= ConfigurationManager()\n",
    "    evaluation_config=config.get_evaluation_ML_config()\n",
    "    evaluation=Evaluation(evaluation_config)\n",
    "    evaluation.evaluation()\n",
    "    evaluation.log_into_mlflow() \n",
    "except Exception as e:\n",
    "    raise e\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
